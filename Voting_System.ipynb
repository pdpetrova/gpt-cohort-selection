{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Система выбора подходящих медицинских записей"
      ],
      "metadata": {
        "id": "JEXODH-JNCLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "По итогам тестирования модели выберем модель голосования как наиболее успешную модель, так как мера precision у метки YES у этой модели наибольшая, а значит, более точно отбираются те пациенты, которые действительно подходят под критерии исследования.\n",
        "\n",
        "В соответствии с этим выбором построим систему, которая по заданному тексту критериев исследования будет отбирать из базы (папки с медицинскими записями с .txt формате) подходящие медицинские записи и выдавать название соответствующего файла."
      ],
      "metadata": {
        "id": "qIOBM4-HOkZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prerequisites"
      ],
      "metadata": {
        "id": "Fp5tBWJTQzZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17032e4-0dde-411b-aaaf-ef7619e701d1",
        "id": "dNPX5oW-Q47H"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.188-py3-none-any.whl (969 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.4/969.4 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.188 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43db55a-3871-4fd5-8b31-ca83f1588cfe",
        "id": "ZBxNMRkrQ47I"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.7\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o31lVZbSQ47I"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUd7FEQcQ47J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU2FPvthQ47J"
      },
      "outputs": [],
      "source": [
        "TOKEN = #вставить ключ openAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob"
      ],
      "metadata": {
        "id": "V8cn5zS8SszD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Определение всех моделей, участвующих в модели голосования"
      ],
      "metadata": {
        "id": "ujyjxYW0PGIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strict_forward = \"\"\"Read the clinical trial criteria provided below. After that, decide by the patient's medical record if the patient is suitable for the trial. Answer YES or NO only.  \n",
        "\n",
        "Clinical Trial Criteria: {trial}\n",
        "\n",
        "Medical Record: {record}\n",
        "\n",
        "Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=strict_forward, input_variables=[\"trial\", \"record\"]\n",
        ")\n",
        "llm = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1, temperature=0)\n"
      ],
      "metadata": {
        "id": "ZAyDB9NoNONf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm4 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "trial_preprocess = \"\"\"Rewrite and print the clinical trial text following the next rules:\n",
        "1. If there is an age criterion:\n",
        "1.1 If there is a minimum and maximum age, rewrite the age criterion as 'Age: x-y years old', where x is the minimum age and y is the maximum age.\n",
        "1.2 If there is no minimum age, rewrite the age criterion as 'Age: 0-x years old', where x is the maximum age.\n",
        "1.3 If there is no maximum age, rewrite the age criterion as 'Age: x and older', where x is the minimum age\n",
        "2. If there is a gender criterion, rename gender criterion to sex criterion.\n",
        "3. If there is a weight criterion, convert weight to kilograms.\n",
        "4. If there is a height criterion, convert height to meters.\n",
        "5. Do not generate new information.\n",
        "\n",
        "Clinical Trial Text: {trial}\n",
        "Result:\"\"\"\n",
        "PROMPT4 = PromptTemplate(\n",
        "    template=trial_preprocess, input_variables=['trial'])\n",
        "chain1 = LLMChain(llm=llm4, prompt=PROMPT4, output_key='preprocessed_trial')\n",
        "\n",
        "llm5 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "record_preprocess = \"\"\"Rewrite and print the medical record text following the next rules:\n",
        "1. If the patient's weight is mentioned, convert weight to kilograms.\n",
        "2. If the patient's height is mentioned, convert height to meters.\n",
        "3. Do not generate new information.\n",
        "\n",
        "Medical Record Text: {record}\n",
        "Result:\"\"\"\n",
        "PROMPT5 = PromptTemplate(\n",
        "    template=record_preprocess, input_variables=['record'])\n",
        "chain2 = LLMChain(llm=llm5, prompt=PROMPT5, output_key='preprocessed_record')\n",
        "\n",
        "strict_forward = \"\"\"Read the clinical trial criteria provided below. After that, decide by the patient's medical record if the patient is suitable for the trial. Answer YES or NO only.  \n",
        "\n",
        "Clinical Trial Criteria: {preprocessed_trial}\n",
        "\n",
        "Medical Record: {preprocessed_record}\n",
        "\n",
        "Answer:\"\"\"\n",
        "simplePROMPT = PromptTemplate(\n",
        "    template=strict_forward, input_variables=[\"preprocessed_trial\", \"preprocessed_record\"]\n",
        ")\n",
        "llm0 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1, temperature=0)\n",
        "simple_chain = LLMChain(llm=llm0, prompt=simplePROMPT, output_key='answer')"
      ],
      "metadata": {
        "id": "FrC0kL4CPZYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "criteria_list = \"\"\"Print all criteria from the given clinical trial as one list with points. Start each point with 'Must'.\n",
        "Example:\n",
        "  - Must be between 15 and 25 years old.\n",
        "  - Must not have HIV.\n",
        "  - Must not be pregnant.\n",
        "\n",
        "\n",
        "Clinical Trial: {trial}.\n",
        "\n",
        "List of criteria:\"\"\"\n",
        "PROMPT1 = PromptTemplate(\n",
        "    template=criteria_list, input_variables=['trial'])\n",
        "chain3 = LLMChain(llm=llm1, prompt=PROMPT1, output_key='criteria_list')\n",
        "\n",
        "llm2 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=1)\n",
        "yes_no_list = \"\"\"Given the medical record and the criteria list, for each criterion of the list print YES if the patient fits the criterion, or print NO if the patient does not fit the criterion.\n",
        "Follow these rules:\n",
        "  1. If any disease from the criterion is not mentioned in the medical record, the patient does not have it.\n",
        "  2. If the activity from the criterion is not mentioned in the medical record, the patient does not have any limitations to perform it.\n",
        "  3. If the point starts with 'Must', the patient must fall under the criterion.\n",
        "  4. If the point starts with 'Must not', the patient must fall under the criterion.\n",
        "  5. If the criterion lists some points with 'or', the patient must fall under at least one criterion from the list.\n",
        "  6. If the criterion lists some points with 'and', the patient must fall under all criteria from the list.\n",
        "\n",
        "Criteria List: {criteria_list}.\n",
        "Medical Record: {record}\n",
        "\n",
        "List of YES and NO:\"\"\"\n",
        "PROMPT2 = PromptTemplate(\n",
        "    template=yes_no_list, input_variables=['criteria_list', 'record'])\n",
        "chain4 = LLMChain(llm=llm2, prompt=PROMPT2, output_key='tagged_list')\n",
        "\n",
        "llm3 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1, temperature=1)\n",
        "yes_no_answer = \"\"\"Read the criteria list with YES or NO tags.\n",
        "If the tags are all YES, print YES only. If there is at least one NO, print NO only.\n",
        "\n",
        "Criteria List: {tagged_list}\n",
        "\n",
        "Answer:\"\"\"\n",
        "PROMPT3 = PromptTemplate(\n",
        "    template=yes_no_answer, input_variables=['tagged_list'])\n",
        "chain5 = LLMChain(llm=llm3, prompt=PROMPT3, output_key='answer')\n",
        "\n"
      ],
      "metadata": {
        "id": "7JweL0K2P8GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm4 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "trial_preprocess = \"\"\"Rewrite and print the clinical trial text following the next rules:\n",
        "1. If there is an age criterion:\n",
        "1.1 If there is a minimum and maximum age, rewrite the age criterion as 'Age: x-y years old', where x is the minimum age and y is the maximum age.\n",
        "1.2 If there is no minimum age, rewrite the age criterion as 'Age: 0-x years old', where x is the maximum age.\n",
        "1.3 If there is no maximum age, rewrite the age criterion as 'Age: x and older', where x is the minimum age\n",
        "2. If there is a gender criterion, rename gender criterion to sex criterion.\n",
        "3. If there is a weight criterion, convert weight to kilograms.\n",
        "4. If there is a height criterion, convert height to meters.\n",
        "5. Do not generate new information.\n",
        "\n",
        "Clinical Trial Text: {trial}\n",
        "Result:\"\"\"\n",
        "PROMPT4 = PromptTemplate(\n",
        "    template=trial_preprocess, input_variables=['trial'])\n",
        "chain11 = LLMChain(llm=llm4, prompt=PROMPT4, output_key='preprocessed_trial')\n",
        "\n",
        "llm5 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "record_preprocess = \"\"\"Rewrite and print the medical record text following the next rules:\n",
        "1. If the patient's weight is mentioned, convert weight to kilograms.\n",
        "2. If the patient's height is mentioned, convert height to meters.\n",
        "3. Do not generate new information.\n",
        "\n",
        "Medical Record Text: {record}\n",
        "Result:\"\"\"\n",
        "PROMPT5 = PromptTemplate(\n",
        "    template=record_preprocess, input_variables=['record'])\n",
        "chain22 = LLMChain(llm=llm5, prompt=PROMPT5, output_key='preprocessed_record')\n",
        "\n",
        "llm1 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1500, n=2)\n",
        "criteria_list = \"\"\"Print all criteria for the given clinical trial as one list with points. Start each point with 'Must'.\n",
        "Example:\n",
        "  - Must be between 15 and 25 years old.\n",
        "  - Must not have HIV.\n",
        "  - Must not be pregnant.\n",
        "\n",
        "\n",
        "Clinical Trial: {preprocessed_trial}.\n",
        "\n",
        "List of criteria:\"\"\"\n",
        "PROMPT1 = PromptTemplate(\n",
        "    template=criteria_list, input_variables=['preprocessed_trial'])\n",
        "chain33 = LLMChain(llm=llm1, prompt=PROMPT1, output_key='criteria_list')\n",
        "\n",
        "llm2 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=150, n=1)\n",
        "yes_no_list = \"\"\"Given the medical record and the criteria list, for each criterion of the list print YES if the patient is suitable for the criterion, or print NO if the patient is not suitable for the criterion.\n",
        "Follow these rules:\n",
        "  1. If any disease from the criterion is not mentioned in the medical record, the patient does not have it.\n",
        "  2. If the activity from the criterion is not mentioned in the medical record, the patient does not have any limitations to perform it. \n",
        "  3. If the point starts with 'Must', the patient must fall under the criterion.\n",
        "  4. If the point starts with 'Must not', the patient must fall under the criterion.\n",
        "  5. If the criterion lists some points with 'or', the patient must fall under at least one criterion from the list.\n",
        "  6. If the criterion lists some points with 'and', the patient must fall under all criteria from the list.\n",
        "\n",
        "Criteria List: {criteria_list}.\n",
        "Medical Record: {preprocessed_record}\n",
        "\n",
        "List of YES and NO:\"\"\"\n",
        "PROMPT2 = PromptTemplate(\n",
        "    template=yes_no_list, input_variables=['criteria_list', 'preprocessed_record'])\n",
        "chain44 = LLMChain(llm=llm2, prompt=PROMPT2, output_key='tagged_list')\n",
        "\n",
        "llm3 = ChatOpenAI(openai_api_key=TOKEN, model_name=\"gpt-3.5-turbo\", max_tokens=1, n=1)\n",
        "yes_no_answer = \"\"\"Read the criteria list with YES or NO tags. \n",
        "If the tags are all YES, print YES only. If there is at least one NO, print NO only.\n",
        "\n",
        "Criteria List: {tagged_list}\n",
        "\n",
        "Answer:\"\"\"\n",
        "PROMPT3 = PromptTemplate(\n",
        "    template=yes_no_answer, input_variables=['tagged_list'])\n",
        "chain55 = LLMChain(llm=llm3, prompt=PROMPT3, output_key='answer')"
      ],
      "metadata": {
        "id": "pe4Rup4zQckW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple = LLMChain(llm=llm, prompt=PROMPT)\n",
        "\n",
        "\n",
        "preprocessed_simple = SequentialChain(\n",
        "    chains=[chain1, chain2, simple_chain],\n",
        "    input_variables=[\"trial\", \"record\"],\n",
        "    # Here we return our variable\n",
        "    output_variables=[\"answer\"])\n",
        "\n",
        "list_criteria = SequentialChain(\n",
        "    chains=[chain3, chain4, chain5],\n",
        "    input_variables=[\"trial\", \"record\"],\n",
        "    # Here we return our variable\n",
        "    output_variables=[\"answer\"])\n",
        "\n",
        "preprocessed_list_criteria = SequentialChain(\n",
        "    chains=[chain11, chain22, chain33, chain44, chain55],\n",
        "    input_variables=[\"trial\", \"record\"],\n",
        "    # Here we return our variable\n",
        "    output_variables=[\"answer\"])"
      ],
      "metadata": {
        "id": "3HvLvC1RPShc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Определение модели голосования"
      ],
      "metadata": {
        "id": "ZrgcfTZ6RIXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def voting(criteria, path_to_records, model1=simple, model2=preprocessed_simple, model3=list_criteria, model4=preprocessed_list_criteria):\n",
        "  suitable = []\n",
        "  for filename in glob.glob(os.path.join(path_to_records, '*.txt')):\n",
        "    with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
        "      record = f.read()\n",
        "      ans1 = model1.run({'trial': criteria, 'record': record})\n",
        "      ans2 = model2.run({'trial': criteria, 'record': record})\n",
        "      ans3 = model3.run({'trial': criteria, 'record': record})\n",
        "      ans4 = model4.run({'trial': criteria, 'record': record})\n",
        "      for k in [ans1, ans2, ans3, ans4]:\n",
        "        num = k.count('YES')\n",
        "        if num > 2:\n",
        "          suitable.append(filename)\n",
        "  return suitable"
      ],
      "metadata": {
        "id": "nBS9XyxuScbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Пример работы системы"
      ],
      "metadata": {
        "id": "lCjlGE0MT6HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "2cMlRf37apEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = '''Inclusion Criteria: Must meet one of the following criteria: - Overweight - Previous knee injury or surgery - Knee pain during the past year. Participants do not need to have current knee pain to take part in the study. - Parent or sibling who had knee replacement Exclusion Criteria: - Rheumatoid arthritis - Joint replacements in both knees - Unable to walk without assistance - Unable to undergo MRI of the knee'''"
      ],
      "metadata": {
        "id": "iNJu9WLCT9To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/mag diplom/system'"
      ],
      "metadata": {
        "id": "jL7vdC-aZvR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = voting(criteria, path)"
      ],
      "metadata": {
        "id": "Rhp5TE33aIMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs # к данным критериям не нашлось подходящих документов из представленной папки"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNfwppZMaMWJ",
        "outputId": "26f9d564-a9c9-4725-dc99-3d46ef8a1dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}